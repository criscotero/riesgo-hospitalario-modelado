{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwdcNHRg-dF0"
   },
   "source": [
    "# Final Project - Hospitalization Prediction for Elderly People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxve20X42VBm",
    "outputId": "e90687c3-8a3e-4837-d6f4-eb2ae43667d2"
   },
   "outputs": [],
   "source": [
    "from src import extract_data as data, preprocessing\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *The Mexican Health and Aging Study* (**MHAS**) is a dataset of household surveys designed to collect information on the health, economic status, and quality of life of older adults.\n",
    "The survey was conducted over 5 time periods, technically known as **Waves**. \n",
    "In addition, there are three study subjects: the respondent (r), the spouse (s), and the household (H). For this study we will use the last wave and the respondent(r)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the data for this project, you only need to execute the code below. This will download H_MHAS_c2.sas7bdat file inside the `dataset` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only once, or if you need to rebuild the original data\n",
    "df = data.download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have',df.shape[0],'subjects')\n",
    "print('We have',df.shape[1],'features')\n",
    "print('Head', df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have download the dataset, you only need to execute the code below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: column count mismatch (97 + 279 != 5241)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = data.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "The dataset `H_MHAS_c2.sas7bdat` has 26839 rows and 5241 features.\n",
    "\n",
    "All features are divided into the following sections.\n",
    "\n",
    "- SECTION A: DEMOGRAPHICS, IDENTIFIERS, AND WEIGHTS \n",
    "- SECTION B: HEALTH \n",
    "- SECTION C: HEALTH CARE UTILIZATION AND INSURANCE \n",
    "- SECTION D: COGNITION  \n",
    "- SECTION E: FINANCIAL AND HOUSING WEALTH \n",
    "- SECTION F: INCOME\n",
    "- SECTION G: FAMILY STRUCTURE \n",
    "- SECTION H: EMPLOYMENT HISTORY \n",
    "- SECTION I: RETIREMENT \n",
    "- SECTION J: PENSION \n",
    "- SECTION K: PHYSICAL MEASURES\n",
    "- SECTION L: ASSISTANCE AND CAREGIVING\n",
    "- SECTION M: STRESS \n",
    "- SECTION O: END OF LIFE PLANNING\n",
    "- SECTION Q: PSYCHOSOCIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical and Numerical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = df.select_dtypes(include=['object']).columns\n",
    "numerical_vars = df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "print('Categorical features ' + str(len(categorical_vars)))\n",
    "print('Numerical features ' + str(len(numerical_vars)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will save the features with the possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.save_categorical_features_with_values(df, 'features_with_values.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this study, we will focus on the Respondent\n",
    "* The Householder variable will be removed from data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split waves\n",
    "\n",
    "Our initial approach is to train our model using separate waves. We made this decision because the last three waves took place every two years and there is little data available to helps us bridge that gap, so a cross-sectional cut of the data makes sense as our best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave 5 dataframe has the following shape: (26839, 1004)\n"
     ]
    }
   ],
   "source": [
    "wave_5_df = preprocessing.extract_wave_data(df, \"5\")\n",
    "\n",
    "print(f'Wave 5 dataframe has the following shape: {wave_5_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='split-respondents'></a>\n",
    "### Split respondents\n",
    "\n",
    "Our initial approach is to train the model using only data from the respondents, as we believe it is the most relevant information to properly train our model; also, given that our MPV requires interaction with the people interested in receiving a hospitalization prediction, we deem it best to ask them questions abouth themselves rather than their spouse or household, as such information might not be available during their interaction with our MVP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave 5 respondent-only dataframe has the following shape: (26839, 469)\n"
     ]
    }
   ],
   "source": [
    "wave_5_respondents_df = preprocessing.extract_respondent_data(wave_5_df)\n",
    "\n",
    "print(f'Wave 5 respondent-only dataframe has the following shape: {wave_5_respondents_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.save_categorical_features_with_values(wave_5_respondents_df, 'wave_5_features_with_values.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of the target variable\n",
    "* The target variable belongs to *Section C: Health Care Utilization and Insurance* and is labeled **Medical Care Utilization: Hospital** *`rhosp1y`*\n",
    "\n",
    "* *rhosp1y* indicates whether the respondent reports at least one overnight hospital stay in the last 12 months. RHOSP1Y is coded as 0 if the respondent had no overnight hospital stays, and is coded as 1 if the respondent had at least one overnight hospital stay. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='remove-missing-target'></a>\n",
    "### Remove missing values in target variable\n",
    "\n",
    "Our first step is to remove all rows containing missing values in our target variable. Why remove them instead of imputate them? Because this is our ground truth: We cannot alter it by somehow estimating missing values from the data. If we attempt to imputate our ground truth with other features, we'd be incorporating information about the data into the target variable, which could very likely lead us to overfit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (17046, 469)\n"
     ]
    }
   ],
   "source": [
    "wave_5_respondents_df = preprocessing.remove_missing_values(wave_5_respondents_df, 'r5hosp1y')\n",
    "\n",
    "print(f'Shape: {wave_5_respondents_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.save_categorical_features_with_values(df, 'wave_5_features_with_values.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='drop-high-rate-missing-values-columns'></a>\n",
    "\n",
    "### Drop columns with a high rate of missing values\n",
    "\n",
    "We have decided to drop columns with a high missing values ratio (>0.7). A column with such a high proportion of missing values hints at survey unreliability and it doesn't make much sense to imputate missing values when their proportion is higher than existing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with a missing value ratio higher than 0.2: ['r5rifcare', 'r5mealhlp', 'r5recstrok', 'r5jrsleft', 'r5haluc', 'r5ciqscore15', 'r5toilt', 'r5bath', 'r5rafcarehrm', 'r5rrcaredpm', 'r5riccarehr', 'r5medhlp', 'r5ciqscore8', 'r5rpfcarehr', 'r5ripfcaredpm', 'r5fallinj', 'r5rapfcarehrm', 'r5rechrtatt', 'r5rascarehr', 'r5jlasty', 'r5ciqscore7', 'r5jhours', 'radyear', 'r5rfcaren', 'r5riscarehr', 'r5rifaany', 'r5rfcarehr', 'r5prchmem', 'r5bede', 'r5eathlp', 'r5eat', 'r5rrcaredpmm', 'r5ciqscore16', 'r5raccaredpm', 'r5rrcaren', 'r5lstmnspd', 'r5flstmnspd', 'r5walkre', 'r5rarcaren', 'r5rscare', 'r5raccarehrm', 'r5rpfcaren', 'r5mammog', 'r5rcaany', 'r5jcten', 'r5ciqscore1', 'r5rafcaren', 'r5stroklmt', 'r5rccaredpm', 'r5rafcaredpm', 'r5rrcarehr', 'r5breast', 'r5unemp', 'r5rifcarehr', 'r5racaany', 'r5ciqscore4', 'r5rapfcare', 'r5rascare', 'r5rpfcaredpm', 'r5rscarehrm', 'r5wander', 'r5ricany', 'r5walkr', 'r5jredhr', 'r5strtsmok', 'r5penic', 'r5ciqscore10', 'r5ciqscore11', 'r5rorgnz', 'r5rascaredpm', 'r5rafcaredpmm', 'r5rpfcare', 'r5hystere', 'r5bed', 'r5penage', 'r5prost', 'r5ciqscore14', 'r5rapfcarehr', 'r5lost', 'r5rccarehrm', 'r5raccarehr', 'r5rscarehr', 'r5riccare', 'r5riscarehrm', 'r5retage', 'r5walkhlp', 'r5rifcaredpmm', 'r5rircare', 'r5ripfcaren', 'r5rccaren', 'r5ciqscore13', 'r5rapfcaredpmm', 'r5raccaredpmm', 'r5rjudg', 'r5rafcare', 'r5rafcarehr', 'r5rascaredpmm', 'r5ssic', 'r5riscaredpmm', 'r5ciqscore3', 'r5resplmt', 'r5prmem', 'r5raccaren', 'r5rrcare', 'r5ciqscore5', 'r5ciqscore2', 'r5bedhlp', 'r5rircaredpm', 'r5jlocc_m', 'r5bathehlp', 'r5arthlmt', 'r5toilethlp', 'r5rfcaredpmm', 'r5lifein_m', 'r5ripfcarehrm', 'r5rscaredpm', 'r5rircaredpmm', 'r5rarcarehrm', 'r5ripfcare', 'r5riccaredpmm', 'r5pubage', 'r5ripfcaredpmm', 'r5retyr', 'r5reccancr', 'r5rfcare', 'r5rascarehrm', 'r5rfcaredpm', 'r5rapfcaren', 'r5paina', 'r5rccare', 'r5rpfcaredpmm', 'r5ciqscore12', 'r5rarcarehr', 'r5riccaren', 'r5cjormscore', 'r5rscaredpmm', 'r5rfcarehrm', 'r5rafaany', 'r5moneyhlp', 'r5ricaany', 'r5rircarehr', 'r5rifcaren', 'r5rifcarehrm', 'r5rapfcaredpm', 'r5rircaren', 'r5riccarehrm', 'r5ciqscore9', 'r5rcany', 'r5slfemp', 'r5hrtatlmt', 'r5ciqscore6', 'r5riscaredpm', 'r5ripfcarehr', 'r5rarcaredpmm', 'r5riscare', 'r5rrcarehrm', 'r5rarcaredpm', 'radmonth', 'r5racany', 'r5shophlp', 'r5rfaany', 'r5papsm', 'r5quitsmok', 'r5rccaredpmm', 'r5dresshlp', 'r5rifcaredpm', 'r5rarcare', 'r5rircarehrm', 'r5rccarehr', 'r5raccare', 'r5riccaredpm', 'r5alone', 'r5rpfcarehrm']\n",
      "Count of variables with a missing ratio higher than 0.2: 173\n",
      "New column count: 296\n"
     ]
    }
   ],
   "source": [
    "variables_to_drop = preprocessing.missing_value_ratio(wave_5_respondents_df, 0.2)\n",
    "\n",
    "# Drop the columns with specified missing values ratio\n",
    "wave_5_respondents_df = wave_5_respondents_df.drop(columns=variables_to_drop)\n",
    "\n",
    "# Verify columns were droped. Starting column count is 469\n",
    "print(f'New column count: {wave_5_respondents_df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features with their unique values have been saved to 'wave_5_features_out_missing_value.txt'\n"
     ]
    }
   ],
   "source": [
    "preprocessing.save_categorical_features_with_values(wave_5_respondents_df, 'wave_5_features_out_missing_value.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37puETfgRzzg"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wc5LLfBi4tM_"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrqVq9iz44nA",
    "outputId": "7eba6e5b-9ebd-4adc-ff04-25d83b8e91c7"
   },
   "outputs": [],
   "source": [
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rM2hK1k45Ra",
    "outputId": "9cd230b2-fb74-4b5d-e63e-0431dae83ba9"
   },
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Htn8h46b7vAX",
    "outputId": "8cbf7717-9bd7-49b7-f6e9-88eb9dff3df1"
   },
   "outputs": [],
   "source": [
    "columns_list = list(df.columns)\n",
    "print(columns_list)\n",
    "\n",
    "num_columns = len(df.columns)\n",
    "print(f\"The dataset contains {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZM7C_xcW4-ul",
    "outputId": "555c0ee1-2b7a-4bbe-c0f4-58b36633e6eb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Basic Information\n",
    "print(\"Basic Info:\")\n",
    "print(df.info())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Summary Statistics:\")\n",
    "print(df.describe(include='all'))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"Duplicate Rows:\")\n",
    "print(df.duplicated().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTaWJboJ7gyR"
   },
   "outputs": [],
   "source": [
    "\n",
    "target_column = 'your_target_column'\n",
    "if target_column in df.columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x=target_column, data=df)\n",
    "    plt.title(f'Target Column Distribution: {target_column}')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
