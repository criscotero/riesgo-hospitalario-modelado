{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "Add a a general description of how and why data was preprocessed\n",
    "\n",
    "## Sections \n",
    "[Split waves](#split-waves)  \n",
    "[Split respondents](#split-respondents)  \n",
    "[Remove missing values in target variable](#remove-missing-target)  \n",
    "[Drop columns with a high rate of missing values](#drop-high-rate-missing-values-columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'H_MHAS_c2.dta'\n",
    "raw_df = pd.read_stata(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='split-waves'></a>\n",
    "### Split waves\n",
    "\n",
    "Our initial approach is to train our model using separate waves. We made this decision because the last three waves took place every two years and there is little data available to helps us bridge that gap, so a cross-sectional cut of the data makes sense as our best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave 5 dataframe has the following shape: (26839, 1004)\n"
     ]
    }
   ],
   "source": [
    "wave_5_df = preprocessing.extract_wave_data(raw_df, \"5\")\n",
    "\n",
    "print(f'Wave 5 dataframe has the following shape: {wave_5_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='split-respondents'></a>\n",
    "### Split respondents\n",
    "\n",
    "Our initial approach is to train the model using only data from the respondents, as we believe it is the most relevant information to properly train our model; also, given that our MPV requires interaction with the people interested in receiving a hospitalization prediction, we deem it best to ask them questions abouth themselves rather than their spouse or household, as such information might not be available during their interaction with our MVP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave 5 respondent-only dataframe has the following shape: (26839, 469)\n"
     ]
    }
   ],
   "source": [
    "wave_5_respondents_df = preprocessing.extract_respondent_data(wave_5_df)\n",
    "\n",
    "print(f'Wave 5 respondent-only dataframe has the following shape: {wave_5_respondents_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='remove-missing-target'></a>\n",
    "### Remove missing values in target variable\n",
    "\n",
    "We need to make sure that our wave data is appropriate for modeling. This includes removing missing values in our target variable and imputating missing values in other columns. Imputation of categorical variables is not as straightforward as imputation of numerical variables, thus, we'll have to take several steps to complete this task.\n",
    "\n",
    "Our first step is to remove all rows containing missing values in our target variable. Why remove them instead of imputate them? Because this is our ground truth: We cannot alter it by somehow estimating missing values from the data. If we attempt to imputate our ground truth with other features, we'd be incorporating information about the data into the target variable, which could very likely lead us to overfit our model.\n",
    "\n",
    "Our target variable is 'r5hosp1y', which encodes a 'yes' or 'no' question on whether the respondent has had at least one overnight hospital stay in the last 12 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable now has values: [0, 1]\n",
      "Categories (2, int64): [0 < 1]\n"
     ]
    }
   ],
   "source": [
    "wave_5_respondents_df = preprocessing.remove_missing_values(wave_5_respondents_df, 'r5hosp1y')\n",
    "\n",
    "\n",
    "# Check that there are no values other tan 0 and 1\n",
    "print(f\"Target variable now has values: {wave_5_respondents_df['r5hosp1y'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to check for deceased respondents. Variable 'r5iwstat' encodes informartion on whether the respondent is alive or deceased. The value 1 is assigned to respondents who are alive. The code block below verifies that, indeed, all respondents are alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.Resp, alive']\n",
      "Categories (6, object): ['0.Inap' < '1.Resp, alive' < '4.NR, alive' < '5.NR, died this wave' < '6.NR, died prev wave' < '9.NR, dk if alive or died']\n"
     ]
    }
   ],
   "source": [
    "print(wave_5_respondents_df['r5iwstat'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='drop-high-rate-missing-values-columns'></a>\n",
    "\n",
    "### Drop columns with a high rate of missing values\n",
    "\n",
    "We have decided to drop columns with a high missing values ratio (>0.7). A column with such a high proportion of missing values hints at survey unreliability and it doesn't make much sense to imputate missing values when their proportion is higher than existing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with a missing value ratio higher than 0.1: ['r5ciqscore6', 'r5rifcaredpmm', 'r5rccarehr', 'r5dresshlp', 'r5wander', 'r5rrcarehr', 'r5rrcaredpm', 'r5bed', 'r5racaany', 'r5pubage', 'r5bmi', 'r5strtsmok', 'r5bedhlp', 'r5rfaany', 'r5rpfcaren', 'r5rifcaredpm', 'r5walkr', 'r5rifcarehr', 'r5ssic', 'r5rfcaredpm', 'r5rfcarehrm', 'r5rfcarehr', 'r5toilt', 'r5rapfcaredpm', 'r5hystere', 'r5raccarehr', 'r5riscarehr', 'r5ciqscore4', 'r5rpfcaredpmm', 'r5ciqscore5', 'r5rccaren', 'r5shophlp', 'r5alone', 'r5moneyhlp', 'r5recstrok', 'r5rscaredpm', 'r5rccarehrm', 'r5rafcare', 'r5rafcarehr', 'r5ripfcarehrm', 'r5ciqscore12', 'r5ciqscore16', 'r5riscaredpmm', 'r5rcany', 'r5stroklmt', 'r5rarcarehr', 'r5rrcaredpmm', 'r5rscaredpmm', 'r5prchmem', 'r5ciqscore2', 'r5rircaren', 'r5rifcarehrm', 'r5rechrtatt', 'r5ciqscore11', 'r5rorgnz', 'r5retyr', 'r5mealhlp', 'r5bede', 'r5papsm', 'r5arthlmt', 'r5cjormscore', 'r5ciqscore3', 'r5rcaany', 'r5rifaany', 'r5rccaredpm', 'r5rapfcaredpmm', 'r5ciqscore8', 'r5riscarehrm', 'r5ripfcarehr', 'r5unemp', 'r5rafcarehrm', 'r5ciqscore13', 'r5rpfcare', 'r5dadage', 'r5ricaany', 'r5bath', 'r5hrtatlmt', 'r5eat', 'r5fallinj', 'r5rarcare', 'r5lost', 'r5slfemp', 'r5raccare', 'r5riccaredpm', 'r5riscaredpm', 'r5penage', 'r5rapfcaren', 'r5rifcaren', 'r5walkhlp', 'r5ripfcaren', 'r5rarcaredpmm', 'r5rccare', 'r5rccaredpmm', 'r5ricany', 'r5flstmnspd', 'r5ciqscore15', 'rameduc_m', 'r5ripfcare', 'radmonth', 'r5walkre', 'r5paina', 'r5racany', 'r5rascarehrm', 'r5quitsmok', 'r5rircarehr', 'r5ciqscore9', 'r5prmem', 'r5jredhr', 'r5rarcarehrm', 'r5raccarehrm', 'r5rascarehr', 'r5rircaredpm', 'r5jlocc_m', 'r5climsa', 'r5rafcaren', 'r5lstmnspd', 'r5raccaren', 'r5rpfcarehr', 'r5jlasty', 'r5rscarehr', 'r5breast', 'r5rfcaredpmm', 'r5jcten', 'r5lifein_m', 'r5rrcare', 'r5ripfcaredpm', 'r5toilethlp', 'r5ciqscore1', 'r5rifcare', 'r5rjudg', 'r5riccaren', 'r5rpfcaredpm', 'r5rafaany', 'r5jrsleft', 'r5bathehlp', 'r5resplmt', 'r5prost', 'r5rascaredpm', 'r5rarcaredpm', 'r5rascaredpmm', 'r5rrcaren', 'r5rfcare', 'r5penic', 'r5rircare', 'r5ciqscore14', 'r5riscare', 'r5riccaredpmm', 'r5riccarehrm', 'r5mammog', 'r5rascare', 'r5ciqscore7', 'r5retage', 'r5raccaredpm', 'r5rrcarehrm', 'r5rarcaren', 'r5rapfcare', 'r5joga', 'r5raccaredpmm', 'r5rircaredpmm', 'r5rapfcarehrm', 'rafeduc_m', 'r5rafcaredpmm', 'radyear', 'r5riccare', 'r5riccarehr', 'r5haluc', 'r5ciqscore10', 'r5jhours', 'r5rafcaredpm', 'r5rfcaren', 'r5rpfcarehrm', 'r5rscare', 'r5medhlp', 'r5mealsa', 'r5ripfcaredpmm', 'r5eathlp', 'r5reccancr', 'r5rapfcarehr', 'r5rircarehrm', 'r5rscarehrm']\n",
      "Count of variables with a missing ratio higher than 0.1: 180\n",
      "New column count: 289\n"
     ]
    }
   ],
   "source": [
    "variables_to_drop = preprocessing.missing_value_ratio(wave_5_respondents_df, 0.1)\n",
    "\n",
    "# Drop the columns with specified missing values ratio\n",
    "wave_5_respondents_df = wave_5_respondents_df.drop(columns=variables_to_drop)\n",
    "\n",
    "# Verify columns were droped. Starting column count is 469\n",
    "print(f'New column count: {wave_5_respondents_df.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['r5fdlrc8', 'r5beda', 'r5jog', 'r5ifsret', 'r5flusht', 'r5lideal3',\n",
      "       'r5lgmusaa', 'r5hip', 'r5diabe', 'r5hibpe',\n",
      "       ...\n",
      "       'r5nagi8a', 'r5swell', 'r5iadlfoura', 'r5stoop', 'r5lchnot3',\n",
      "       'r5rxhrtat', 'r5walk1a', 'r5medsa', 'r5dadliv', 'r5lifta'],\n",
      "      dtype='object', length=206)\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = wave_5_respondents_df.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Categorical columns:\", categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r5iadlfourm       0\n",
      "r5finea        1331\n",
      "r5fdlrc8          0\n",
      "r5uppermobm       0\n",
      "r5beda          107\n",
      "               ... \n",
      "r5iothr          20\n",
      "r5walk1a       1369\n",
      "r5medsa        1401\n",
      "r5dadliv        265\n",
      "r5lifta        1482\n",
      "Length: 289, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(wave_5_respondents_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r5iadlfourm     float64\n",
      "r5finea         float64\n",
      "r5fdlrc8       category\n",
      "r5uppermobm     float64\n",
      "r5beda         category\n",
      "                 ...   \n",
      "r5iothr         float32\n",
      "r5walk1a       category\n",
      "r5medsa        category\n",
      "r5dadliv       category\n",
      "r5lifta        category\n",
      "Length: 289, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(wave_5_respondents_df.dtypes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
